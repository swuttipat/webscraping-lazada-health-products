{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416dc05e-527e-49bb-b58c-baab5c6a08f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import concurrent.futures\n",
    "from concurrent.futures import as_completed\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_last_page(sec_name, sec_url):\n",
    "\n",
    "    section_url = f'https://www.lazada.co.th{sec_url}?page=1'\n",
    "    \n",
    "    print(f'Processing {sec_name} Section...')\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(section_url)\n",
    "\n",
    "    print(f'Searching for {sec_name} Section Last Page...')\n",
    "\n",
    "    element = driver.find_element(By.CLASS_NAME, 'e5J1n')\n",
    "    li_elements = element.find_elements(By.TAG_NAME, 'li')\n",
    "    new_li_elements = [li.text for li in li_elements]\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "    return int(new_li_elements[-2])  # -2 because the last element is \"Next Page\"\n",
    "\n",
    "\n",
    "\n",
    "def scrape_page(page_number, sec_name, section_url):\n",
    "\n",
    "    \n",
    "    try:\n",
    "        url = f\"{section_url}/?page={page_number}\"\n",
    "\n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "        options.add_argument('--no-sandbox')\n",
    "        options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(url)\n",
    "\n",
    "        product_divs = driver.find_elements_by_css_selector('div[data-qa-locator=\"product-item\"]')\n",
    "\n",
    "        products = []\n",
    "        for div in product_divs:\n",
    "            # ... extract product details ...\n",
    "            product_id = div.get_attribute('data-item-id')  # Extracting product ID\n",
    "            product_section = sec_name\n",
    "            product_name = div.find_element_by_css_selector('a[title]').get_attribute('title')\n",
    "            product_price = div.find_element_by_css_selector('span.ooOxS').text\n",
    "            \n",
    "            try : \n",
    "                product_sold = div.find_element_by_css_selector('span._1cEkb span').text\n",
    "            except : \n",
    "                product_sold = np.nan\n",
    "\n",
    "            try : \n",
    "                product_review = div.find_element_by_css_selector('span.qzqFw').text\n",
    "            except:\n",
    "                product_review = np.nan\n",
    "        \n",
    "            try :\n",
    "                product_location = div.find_element_by_css_selector('span.oa6ri').get_attribute('title')\n",
    "            except:\n",
    "                prodcut_location = np.nan\n",
    "                \n",
    "            product_url = div.find_element_by_css_selector('a[href]').get_attribute('href')\n",
    "\n",
    "\n",
    "            products.append((product_id,\n",
    "                             product_section,\n",
    "                             product_name,\n",
    "                             product_price,\n",
    "                             product_sold,\n",
    "                             product_review,\n",
    "                             product_location,\n",
    "                             product_url,\n",
    "                             page_number))\n",
    "\n",
    "    except Exception as exc:\n",
    "        print(f\"scrape_page ==> An error occurred on page {page_number}: {exc}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        if products != []:\n",
    "            # print(f\"{len(products)} products were found in {sec_name}\")\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"Error occured in page {page_number} of {sec_name}\")\n",
    "\n",
    "    return products\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scrape_section(sec_name, sec_url, last_pages):\n",
    "        \n",
    "    print('='*10 + f'START of {sec_name} Section' + '='*10)\n",
    "    print(f'{sec_name} Section total pages : {last_pages[sec_name]}')\n",
    "    print(f'Web scrapping {sec_name} Section...')\n",
    "    \n",
    "    section_url = f'https://www.lazada.co.th{sec_url}'\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        pages = list(range(1, last_pages[sec_name] + 1))\n",
    "        futures = {executor.submit(scrape_page, page, sec_name, section_url) for page in pages}\n",
    "        \n",
    "        results = []\n",
    "        for future in tqdm(as_completed(futures), total=len(pages)):\n",
    "            results.append(future.result())\n",
    "\n",
    "    flattened_results = [product for sublist in results for product in sublist]\n",
    "\n",
    "    df = pd.DataFrame(flattened_results, columns=['Id', 'Section', 'Name', 'Price', 'Total Sold', 'Total Reviews', 'Shop Location', 'URL', 'Catalog Pages'])\n",
    "\n",
    "    print(f'{len(df)} rows of products were created')\n",
    "    print('='*10 + f'END of {sec_name} Section' + '='*10)\n",
    "    print(\"\\n\\n\\n\")\n",
    "    \n",
    "    return df\n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "def save_dataframe(dataframe, name, time):\n",
    "\n",
    "    # Concatenate the timestamp to the file name\n",
    "    file_name = f\"{name}_{time}.csv\"\n",
    "\n",
    "    # Save the DataFrame to a CSV file with the updated file name\n",
    "    dataframe.to_csv(file_name, index=False)\n",
    "                 \n",
    "\n",
    "\n",
    "\n",
    "health_section = {\n",
    "    \"Acne Care\": \"/shop-acne-care/\",\n",
    "    \"Beauty Supplements Value Sets\": \"/shop-beauty-supplements-gifts/\",\n",
    "    \"Breast Enlargement\": \"/shop-breast-enlargement-supplements/?spm=a2o4m.searchlistcategory.funnel_filter.d1.1e4f4a5cyLrE1m\",\n",
    "    \"Well Being Gifts & Value Sets\": \"/shop-well-being-gifts/\",\n",
    "    \"Bone & Joint Support\": \"/shop-bones-joints/\",\n",
    "    \"Skin Nourishment\": \"/shop-skin-supplements/\",\n",
    "    \"Multivitamins\": \"/shop-multivitamin-supplements/\",\n",
    "    \"Digestive Care\": \"/shop-digestion-and-absorption/\",\n",
    "    \"Herbs & Traditional Medicine\": \"/shop-herbs-traditional-medicine/\",\n",
    "    \"Whitening\": \"/shop-whitening-supplements/\",\n",
    "    \"Nutritional Foods & Drinks\": \"/shop-nutritional-foods-drinks/\",\n",
    "    \"Brain & Memory\": \"/shop-brain-memory/\",\n",
    "    \"Immunity\": \"/shop-immune-system/\",\n",
    "    \"Protein\": \"/shop-protein/\",\n",
    "    \"Slimming Beverages\": \"/shop-slimming-beverages/\",\n",
    "    \"Heart & Blood Pressure\": \"/shop-heart-cholesterol/\",\n",
    "    \"Men's Health\": \"/shop-mens-health/\",\n",
    "    \"Stress, Sleep, and Anxiety\": \"/shop-stress-anxiety-and-depression/\",\n",
    "    \"Hair & Nail\": \"/shop-hair-nail-supplements/\",\n",
    "    \"Sexual Health Vitamins\": \"/shop-sexual-health/\",\n",
    "    \"Appetite Suppressant\": \"/shop-appetite-suppressants/\",\n",
    "    \"Women's Health\": \"/shop-women-and-menopause/\",\n",
    "    \"Meal Replacement\": \"/shop-meal-replacement/\",\n",
    "    \"Weight Management Value Sets\": \"/shop-weight-management-gifts/\",\n",
    "    \"Fat Blockers & Burners\": \"/shop-fat-burners/\",\n",
    "    \"Pre-Workout\": \"/shop-pre-workout/\",\n",
    "    \"Mass Gainer\": \"/shop-weight-gain-supplements/\",\n",
    "    \"Detoxification\": \"/shop-liver-detox/\",\n",
    "    \"Pregnancy Care\": \"/shop-pregnancy-care/\",\n",
    "    \"Food Supplement\": \"/shop-health-food-supplements-weight-management/\"\n",
    "}\n",
    "\n",
    "\n",
    "def create_lastPagesDict():\n",
    "    \n",
    "    ''' \n",
    "    Create dictionary contain number of last page \n",
    "    '''\n",
    "\n",
    "    last_pages = {}\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(get_last_page, sec_name, sec_url): sec_name for sec_name, sec_url in health_section.items()}\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        sec_name = futures[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "            last_pages[sec_name] = data\n",
    "        except Exception as exc:\n",
    "            print(f'Error occured while finding last pages in {sec_name}\\n generated an exception: {exc}')\n",
    "        else:\n",
    "            print(f'{sec_name} Page Number is: {data}')\n",
    "\n",
    "    print('='*15 + f'Finding Last Pages END' + '='*15)\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    return last_pages\n",
    "        \n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41716ea2-403a-4eb4-a120-c9be23769c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Food Supplement': 102}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-build last_pages dictionaty\n",
    "import pandas as pd\n",
    "d = pd.read_csv('last_pages_dict_20230808_125116.csv', )\n",
    "last_pages = dict(d.values)\n",
    "last_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fbfb92c-e290-4bc4-98b3-d1a4ae291e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========START of Acne Care Section==========\n",
      "Error : 'Acne Care'\n",
      "==========START of Beauty Supplements Value Sets Section==========\n",
      "Error : 'Beauty Supplements Value Sets'\n",
      "==========START of Breast Enlargement Section==========\n",
      "Error : 'Breast Enlargement'\n",
      "==========START of Well Being Gifts & Value Sets Section==========\n",
      "Error : 'Well Being Gifts & Value Sets'\n",
      "==========START of Bone & Joint Support Section==========\n",
      "Error : 'Bone & Joint Support'\n",
      "==========START of Skin Nourishment Section==========\n",
      "Error : 'Skin Nourishment'\n",
      "==========START of Multivitamins Section==========\n",
      "Error : 'Multivitamins'\n",
      "==========START of Digestive Care Section==========\n",
      "Error : 'Digestive Care'\n",
      "==========START of Herbs & Traditional Medicine Section==========\n",
      "Error : 'Herbs & Traditional Medicine'\n",
      "==========START of Whitening Section==========\n",
      "Error : 'Whitening'\n",
      "==========START of Nutritional Foods & Drinks Section==========\n",
      "Error : 'Nutritional Foods & Drinks'\n",
      "==========START of Brain & Memory Section==========\n",
      "Error : 'Brain & Memory'\n",
      "==========START of Immunity Section==========\n",
      "Error : 'Immunity'\n",
      "==========START of Protein Section==========\n",
      "Error : 'Protein'\n",
      "==========START of Slimming Beverages Section==========\n",
      "Error : 'Slimming Beverages'\n",
      "==========START of Heart & Blood Pressure Section==========\n",
      "Error : 'Heart & Blood Pressure'\n",
      "==========START of Men's Health Section==========\n",
      "Error : \"Men's Health\"\n",
      "==========START of Stress, Sleep, and Anxiety Section==========\n",
      "Error : 'Stress, Sleep, and Anxiety'\n",
      "==========START of Hair & Nail Section==========\n",
      "Error : 'Hair & Nail'\n",
      "==========START of Sexual Health Vitamins Section==========\n",
      "Error : 'Sexual Health Vitamins'\n",
      "==========START of Appetite Suppressant Section==========\n",
      "Error : 'Appetite Suppressant'\n",
      "==========START of Women's Health Section==========\n",
      "Error : \"Women's Health\"\n",
      "==========START of Meal Replacement Section==========\n",
      "Error : 'Meal Replacement'\n",
      "==========START of Weight Management Value Sets Section==========\n",
      "Error : 'Weight Management Value Sets'\n",
      "==========START of Fat Blockers & Burners Section==========\n",
      "Error : 'Fat Blockers & Burners'\n",
      "==========START of Pre-Workout Section==========\n",
      "Error : 'Pre-Workout'\n",
      "==========START of Mass Gainer Section==========\n",
      "Error : 'Mass Gainer'\n",
      "==========START of Detoxification Section==========\n",
      "Error : 'Detoxification'\n",
      "==========START of Pregnancy Care Section==========\n",
      "Error : 'Pregnancy Care'\n",
      "==========START of Food Supplement Section==========\n",
      "Food Supplement Section total pages : 102\n",
      "Web scrapping Food Supplement Section...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 102/102 [05:03<00:00,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020 rows of products were created\n",
      "==========END of Food Supplement Section==========\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Now total dataframe are 1 sets\n",
      "CPU times: total: 28.4 s\n",
      "Wall time: 5min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Generate the current timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for sec_name, sec_url in health_section.items():\n",
    "    \n",
    "    try :\n",
    "        df = scrape_section(sec_name, sec_url, last_pages)\n",
    "    \n",
    "        # Save output dataframe as csv file\n",
    "        save_dataframe(df, sec_name, timestamp)\n",
    "\n",
    "        dfs.append(df)\n",
    "        print(f'Now total dataframe are {len(dfs)} sets')\n",
    "        \n",
    "    except Exception as exc:\n",
    "        print(f'Error : {exc}')\n",
    "        \n",
    "\n",
    "# df_concatenated = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "# # Save output final dataframe as csv file\n",
    "# save_dataframe(df_concatenated, \"health_and_wellness\", timestamp)\n",
    "# df_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8dfb4-dfd4-49e4-8fd6-9a2b1218d1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd2b352-3fd4-4623-a5b5-0463bfb4bc89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to make a link clickable\n",
    "def make_clickable(val):\n",
    "    return '<a href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "# Apply the function to the 'Product URL' column\n",
    "dfs_styled = df_concatenated.style.format({'Product URL': make_clickable})\n",
    "dfs_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce364266-138d-4db1-9a36-7810d814f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create Dataframe\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming df_concatenated contains your DataFrame\n",
    "\n",
    "# Generate the current timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Concatenate the timestamp to the file name\n",
    "file_name = f\"health_and_wellness_{timestamp}.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file with the updated file name\n",
    "df_concatenated.to_csv(file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44be9bbc-bd97-42aa-81d1-800d32eeb2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-03_16-42-58\n"
     ]
    }
   ],
   "source": [
    "# Generate timestamp\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "current_timestamp = datetime.now()\n",
    "\n",
    "# Custom format for the timestamp\n",
    "custom_format = \"%Y-%m-%d_%H-%M-%S\"\n",
    "\n",
    "# Print the timestamp with the custom format\n",
    "print(current_timestamp.strftime(custom_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b59af5f-139f-4d49-858e-a1ec7a9c5b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_pages = {\n",
    " 'Food Supplement': 102,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d13fdf6-2d6c-4d3c-9552-d305cf1c2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Generate the current timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Concatenate the timestamp to the file name\n",
    "file_name = f\"last_pages_dict_{timestamp}.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file with the updated file name\n",
    "d = pd.DataFrame(last_pages.items())\n",
    "d.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cefc51b-6468-4ab7-a049-fb6d0436ecb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
